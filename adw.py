import os
import ollama
import faiss
import fitz  # PyMuPDF
import pytesseract
import numpy as np
from PIL import Image
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
import streamlit as st
import time
vector_db_path = "faiss_index"

# ------------------- 1. æ–‡æ¡£è§£æ & OCR ------------------- #
def extract_text_from_pdf(pdf_path):
    text = ""
    doc = fitz.open(pdf_path)
    for page in doc:
        text += page.get_text("text")
    return text

# ------------------- 2. ç”Ÿæˆå‘é‡æ•°æ®åº“ ------------------- #
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vector_db = FAISS.from_texts(["dummy text"], embeddings)

def index_text(text, db_path="faiss_index"):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.split_text(text)
    vector_db.add_texts(docs)
    vector_db.save_local(db_path)  # è¿™é‡Œæ”¹ä¸ºä¼ å…¥å‚æ•°
    return "ç´¢å¼•å·²æ›´æ–°ï¼"

# ------------------- 3. RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ ------------------- #
llm = Ollama(model="deepseek-r1:14b")
qa_chain = RetrievalQA.from_chain_type(llm, retriever=vector_db.as_retriever(), chain_type="stuff")

def query_rag(query):
    return qa_chain.run(query)

# ------------------- 4. Agent æ™ºèƒ½ä»»åŠ¡ ------------------- #
def generate_summary(query):
    return f"æ‘˜è¦: è¿™æ˜¯å…³äº '{query}' çš„ç®€è¦æ€»ç»“ã€‚"

def generate_visualization(query):
    return f"ç”Ÿæˆä¸ '{query}' ç›¸å…³çš„æ•°æ®å¯è§†åŒ–..."

def generate_translation(query):
    return f"å°† '{query}' ç¿»è¯‘æˆå¤šç§è¯­è¨€: è‹±æ–‡, è¥¿ç­ç‰™è¯­, æ³•è¯­..."

def generate_code_snippet(query):
    return f"åŸºäº '{query}' ç”Ÿæˆä»£ç ç¤ºä¾‹: \nprint('Hello, {query}')"

tools = [
    Tool(
        name="Document Search",
        func=lambda q: vector_db.similarity_search(q, k=5),
        description="æŸ¥è¯¢æ–‡æ¡£ç›¸å…³å†…å®¹"
    ),
    Tool(
        name="Report Analysis",
        func=lambda q: f"ç”Ÿæˆåˆ†ææŠ¥å‘Š: {q}",
        description="å¯¹æ–‡æ¡£å†…å®¹ç”Ÿæˆç»“æ„åŒ–åˆ†ææŠ¥å‘Š"
    ),
    Tool(
        name="Image Generation",
        func=lambda q: f"ç”Ÿæˆä¸ {q} ç›¸å…³çš„å›¾ç‰‡...",
        description="åŸºäºæŸ¥è¯¢å†…å®¹ç”Ÿæˆç›¸å…³å›¾ç‰‡"
    ),
    Tool(
        name="Summary Generation",
        func=generate_summary,
        description="ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"
    ),
    Tool(
        name="Data Visualization",
        func=generate_visualization,
        description="åŸºäºæ•°æ®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"
    ),
    Tool(
        name="Translation",
        func=generate_translation,
        description="å°†æŸ¥è¯¢å†…å®¹ç¿»è¯‘æˆå¤šç§è¯­è¨€"
    ),
    Tool(
        name="Code Generation",
        func=generate_code_snippet,
        description="åŸºäºæŸ¥è¯¢å†…å®¹ç”Ÿæˆä»£ç ç¤ºä¾‹"
    )
]

agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)

def agent_query(query):
    return agent.run(query)

# ------------------- 5. Streamlit ç•Œé¢ ------------------- #
st.set_page_config(page_title="æ™ºèƒ½æ–‡æ¡£å·¥ä½œæµ (ADW)", layout="wide")
st.title("ğŸ“„ æ™ºèƒ½æ–‡æ¡£å·¥ä½œæµ (ADW)")

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  PDF æ–‡æ¡£", type=["pdf"])
if uploaded_file:
    with st.spinner("ğŸ“„ è§£ææ–‡æ¡£ä¸­..."):
        with open("temp.pdf", "wb") as f:
            f.write(uploaded_file.getbuffer())
        text = extract_text_from_pdf("temp.pdf")
        st.success("âœ… æ–‡æ¡£è§£ææˆåŠŸï¼å¼€å§‹ç´¢å¼•...")
        time.sleep(1)
        st.write(index_text(text, vector_db_path))

# æŸ¥è¯¢è¾“å…¥æ¡†
query = st.text_input("ğŸ” è¯·è¾“å…¥ä½ çš„æŸ¥è¯¢å†…å®¹ï¼š")

col1, col2, col3, col4 = st.columns(4)

with col1:
    if st.button("ğŸ“‘ æ£€ç´¢æ–‡æ¡£"):
        with st.spinner("ğŸ” æ­£åœ¨æ£€ç´¢..."):
            response = query_rag(query)
        st.success("âœ… æ£€ç´¢å®Œæˆï¼")
        st.write(response)

with col2:
    if st.button("ğŸ¤– ä½¿ç”¨æ™ºèƒ½ Agent æŸ¥è¯¢"):
        with st.spinner("ğŸ¤– å¤„ç†ä¸­..."):
            response = agent_query(query)
        st.success("âœ… æŸ¥è¯¢å®Œæˆï¼")
        st.write(response)

with col3:
    if st.button("ğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š"):
        with st.spinner("ğŸ“Š ç”Ÿæˆä¸­..."):
            response = agent.run("ç”Ÿæˆåˆ†ææŠ¥å‘Š: " + query)
        st.success("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        st.write(response)

with col4:
    if st.button("ğŸ“œ ç”Ÿæˆæ‘˜è¦"):
        with st.spinner("ğŸ“œ ç”Ÿæˆä¸­..."):
            response = generate_summary(query)
        st.success("âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆï¼")
        st.write(response)

st.markdown("---")
st.caption("ğŸ“Œ ç”± DeepSeek R1 å’Œ LangChain æä¾›æ”¯æŒ")
